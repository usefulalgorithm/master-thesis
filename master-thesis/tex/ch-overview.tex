
\chapter{Overview}\label{ch:overview}

Let $G$ be a CFG of a program. Our objective is to determine whether a feasible error path exists in $G$. In a more formal convention, consider the set of feasible paths $\Pi \subseteq G$ and the set of error paths $\mathcal{B} \subseteq G$. We call the languages $\DEC	(\Pi)$ and $\DEC(\mathcal{B})$ over the alphabet $\{0,1\}$ as \emph{feasible decision vectors} and \emph{error decision vectors} respectively. If there are no feasible paths that are also error paths, then we can deduce the program is correct, since no feasible path in $G$ can reach any error node $v \in V_e$. In other words, the program is correct if $\DEC(\Pi) \cap \DEC(\mathcal{B}) = \emptyset$. 

Representing $\DEC(\Pi)$, the language of all feasible decision vectors in $G$, is actually quite challenging. In general, this language might not be regular or even computable. In our procedure, we construct a candidate finite automaton $C$ that approximates $\DEC(\Pi)$. Such a candidate automaton is constructed using a \emph{probably approximately correct} (PAC) online automata learning algorithm. PAC learning provides statistical guarantees about the correctness of $C$: $C$ is \emph{$\PAC$}, i.e., with \emph{confidence} $\delta$, the deviation of $L(C)$ from $\DEC(\Pi)$ is less than \emph{error rate} $\epsilon$. A more formal explanation of the terms and reasonings within the PAC learning framework is given in Chapter \ref{ch:PAC}.

Constructing a finite automaton $B$ that accepts the set of all error decision vectors $\DEC(\mathcal{B})$ is much more straightforward in comparison. Intuitively, states of $B$ corresponds to nodes in $G$, the initial state of $B$ corresponds to the initial node of $G$, and the final states of $B$ corresponds to $G$'s error nodes. An edge from a sequential node is mapped to a $\lambda$-transition, and the edges from a branching node to its 0- and 1-successors are mapped over symbols 0 and 1 respectively. We will go into the details of this construction in Chapter \ref{ch:error}.

\begin{figure}
	\centering
	\begin{tikzpicture}[node distance = 2cm, auto]
	\newcommand{\MEM}[0]{\mathit{Mem.}}
	\newcommand{\EQ}[0]{\mathit{Eq.}}
	\tikzstyle{decision} = [diamond, draw, fill=blue!20,
	text width=2.5cm, text centered, inner sep=0pt]
	\tikzstyle{block} = [rectangle, draw, fill=blue!20, 
	text centered, rounded corners, minimum height=0.8cm]
	\tikzstyle{line} = [draw, -latex'];
	
	% Draw Boxes
	
	\draw[rounded corners, fill=green!20]
	(0cm,1cm) rectangle +(6cm,-2cm);
	\node[text centered, text width=6cm] 
	at (3cm,0cm) {\textbf{PAC Automata Learning Algorithm}\\(Chapter \ref{ch:PAC})};
	\draw[rounded corners, fill=yellow!20]
	(0cm,6cm) rectangle +(6cm,-4cm);    
	\node[text badly centered, text width=6cm] at (3cm,5.4cm)
	{\textbf{Mechanical Teacher}};
	\draw[rounded corners, fill=blue!20]
	(0.3cm,5cm) rectangle +(2.5cm,-2.6cm);
	\node[text badly centered, text width=6cm] at (1.55cm,3.7cm) 
	{\text{Resolving}\\
		\text{Membership} \\
		\text{Queries} \\
		\text{(Chapter \ref{ch:mem})}};
	\draw[rounded corners, fill=blue!20]
	(3.2cm,5cm) rectangle +(2.5cm,-2.6cm);
	\node[text badly centered, text width=6cm] at (4.45cm,3.7cm) 
	{\text{Resolving}\\
		\text{Equivalence} \\
		\text{Queries} \\
		\text{by Sampling} \\
		\text{(Chapter \ref{ch:eq})}};
	\draw[rounded corners, fill=red!20]
	(-0.3cm,9.2cm) rectangle +(3cm,-2.9cm);
	\node[text badly centered, text width=6cm] at (1.2cm,7.75cm)
	{\text{Feasible} \\
		\text{Error} \\
		\text{Decision} \\
		\text{Vector} \\
		\text{Found}};
	\draw[rounded corners, fill=cyan!20]
	(3.1cm,9.2cm) rectangle +(3.6cm,-2.9cm);
	\node[text badly centered, text width=6cm] at (4.9cm,7.75cm)
	{\text{System is}\\
		$\PAC$};
	
	% Draw Arrows
	
	\path [line] (1,1) -- node {$\MEM(w)$} (1,2.4);
	\path [line] (1.5,2.4) -- node {yes/no} (1.5,1);
	\path [line] (4.5,1) -- node {$\EQ(C)$} (4.5,2.4);
	\path [line] (5,2.4) -- node {yes/counterexample} (5,1);
	\path [line](0,0) -- (-1,0) -- (-1, 7.25) -- (-0.3, 7.25);
	\path [line](5.7,4.2) -- (7.2,4.2) -- (7.2, 7.25) -- (6.7, 7.25);
	\path [line](5.7,3.2) -- (7.7,3.2) -- (7.7, 9.7) -- (1.2, 9.7) -- (1.2, 9.2);
	\end{tikzpicture}
	\caption{Components of our learning procedure}
	\label{figure:overview}
\end{figure}

An overview of our learning procedure is given in Figure \ref{figure:overview}. This procedure is actually similar in structure to the one of \cite{Angluin87}. There are two main components in the procedure: the \emph{teacher} and the \emph{learning algorithm}. The learning algorithm presents two queries to the teacher: \emph{membership query} ("Is a given decision vector feasible in the program?") and \emph{equivalence query} ("Is a given candidate finite automaton $\PAC$?"). The teacher is omniscient on the program behaviors, thus is able to resolve the queries correctly. Also, the teacher is able to test whether a decision vector is actually an error decision vector. By posing these queries, either the learning algorithm iteratively constructs a $\PAC$ approximation of the program, or our procedure finds a feasible error decision vector.

As with other online learning-based techniques, we need to devise a mechanical teacher that resolves queries presented by the learning algorithm. Resolving membership queries (i.e., membership in the set of feasible decision vectors $\DEC(\Pi)$) is relatively simple. For example, when given a decision vector $d$, we can obtain its corresponding path $\pi$ by unfolding the CFG $G$ according to $d$, and use an off-the-shelf solver to decide whether $\pi$ is feasible or not. (See Chapter \ref{ch:mem})

When the automata learning algorithm infer a candidate finite automaton $C$, we need to check whether $L(C)$ approximates $\DEC(\Pi)$, i.e., whether $C$ is $\PAC$. Since comparing $L(C)$ directly with $\DEC(\Pi)$ is not practical, we employ the sampling-based approximate equivalence technique of PAC learning. While being generally unsound, this technique still provides statistical guarantee about the correctness of the inferred candidate automaton. More details on how equivalence queries are made can be found in \ref{ch:eq}. The details of our learning-based procedure is in Chapter \ref{ch:learning_proc}. 

\todo[inline]{Sampling-based procedure... done by me... probably not very well written?}
In addition to the learning-based procedure, we propose a sampling-based procedure that provides the same statistical guarantees to a program, while excluding the overhead from constructing a candidate automaton in the learning-based procedure. Although the learning-based procedure can synthesize a program model that can be reused for different analyses, it comes with additional cost for model synthesis. The idea behind the sampling-based procedure is also based on PAC learning, but since no effort is spent on constructing a candidate automaton, the statistical guarantees provided by the sampling-based procedure can be much tighter than the learning-based procedure when given the same amount of computational resources. More descriptions on the sampling-based procedure is in \ref{ch:sampling_proc}.

\begin{comment}

Let \method{BasicAnalyzer} denote a recursion-free inductive program analyzer,
and let a program $\prog{P}=\{G^{\fun{main}}\}\cup\{G^{\fun{f}} : \fun{f}\mbox{ is a function}\}$
consist of the CFGs of the $\fun{main}$ function and functions that may be
invoked (transitively) from $\fun{main}$.
Since functions without recursive calls can be replaced by their control flow
graphs after proper variable renaming,
we assume that \prog{P} only contains the $\fun{main}$ and recursive functions.
If \prog{P} does not contain recursive functions,
\method{BasicAnalyzer} is able to check \prog{P} by computing inductive invariants.


When \prog{P} contains recursive functions, we transform $G^{\fun{main}}$ into a
recursion-free program $\underline{G}^{\fun{main}}$. The program $\underline{G}^{\fun{main}}$
under-approximates the computation of $G^{\fun{main}}$. That is, every computation
of $\underline{G}^{\fun{main}}$ is also a computation of $G^{\fun{main}}$. If
\method{BasicAnalyzer} finds an error in $\underline{G}^{\fun{main}}$, our
algorithm terminates and reports it. Otherwise,
\method{BasicAnalyzer} has computed an inductive invariant for the
recursion-free under-approximation $\underline{G}^{\fun{main}}$. Our algorithm
computes function summaries of functions in \prog{P} from the inductive invariant of
$\underline{G}^{\fun{main}}$. It then checks if every function summary
over-approximates the computation of the corresponding function. If
so, the algorithm terminates and reports that all assertions in \prog{P}
are satisfied. If a function summary does not over-approximate the
computation, our algorithm unwinds the recursive function and
reiterates~(Algorithm~\ref{algorithm:overview}).

\begin{algorithm}[htb]
\begin{doublespace}
  \KwIn{A program $\prog{P}=\{G^{\fun{main}}\}\cup\{G^{\fun{f}} : \fun{f}\text{ is a function}\}$}

  $k$ := $0$\;
  $\prog{P}_0$ := $\prog{P}$\;
  \Repeat{\textup{complete?}}
  {
    $k$ := $k + 1$\;
    $\prog{P}_{k}$ := unwind every CFG in $\prog{P}_{k-1}$\;
    \Switch{$\method{BasicAnalyzer}(\underline{G}^{\fun{main}}_k)$}
    {
      \Case{$\mathit{Pass(\Pi (\underline{G}^{\fun{main}}_k, \TT))}$:}
      {    
        $S$ := ComputeSummary$(\prog{P}_k,$ $\Pi (\underline{G}^{\fun{main}}_k, \TT))$
      }
      \lCase{$\mathit{Error}$:}
      {
        \Return $\mathit{Error}$
      }
    }
    complete? := CheckSummary$(\prog{P}_k, S)$\;
  }
  \Return $\mathit{Pass} (\Pi (\underline{G}^{\fun{main}}_k, \TT))$, $S$\;
\end{doublespace}
  \caption{Overview}
  \label{algorithm:overview}
\end{algorithm} 

To see how to under-approximate computation, consider a control flow
graph $G^{\fun{main}}_k$. The
under-approximation $\underline{G}^{\fun{main}}_k$ is 
obtained by substituting the command $\mathtt{assume\ false}$ for
every command with recursive function calls
(Figure~\ref{figure:under-mccarthy91}). The substitution
effectively blocks all recursive invocations. Any computation of
$\underline{G}^{\fun{main}}_k$ hence is also a computation of $G^{\fun{main}}_k$. Note that
$\underline{G}^{\fun{main}}_k$ is recursion-free. \method{BasicAnalyzer} is able to
check the under-approximation~$\underline{G}^{\fun{main}}_k$.
\begin{figure}[htb]
  \centering
    \begin{tikzpicture}[scale=1.2,->,>=stealth',shorten >=1pt,auto,node
      distance=2cm,thick,node/.style={circle,draw,minimum width=0.8cm,inner sep=0}]
      \node[node,label=above:$\fun{main()}$] (0) at (-4, 0) {$s$};
      \node[node] (1) at (-4, -1) {$1$};
      \node[node] (2) at (-4, -2) {$2$};
      \node[node] (3) at (-4, -3) {$3$};
      \node[node] (4) at (-4, -4) {$e$};
      \node[node] (00) at ( 0,  0) {\smallnode{$s_1^{\fun{mc91}}$}};
      \node[node] (01) at (-1, -2) {$1_1$};
      \node[node] (02) at ( 1, -0.8) {$2_1$};
      \node[node] (03) at ( 1, -2) {$3_1$};
      \node[node] (04) at ( 1, -3.2) {$4_1$};
      \node[node] (05) at ( 0, -4) {\smallnode{$e_1^{\fun{mc91}}$}};

      \path
        (0) edge 
            node [left] {$\mathtt{assume\ n >= 0}$} (1)
        (1) edge [bend left=15]
            node [above] {$\mathtt{m_1 := n}$} (00)
        (2) edge
            node [left] {$
              \begin{array}{l}
                \mathtt{assert\ {[}r = 91\ or}\\
                \mathtt{\ \ \ \ \ \ \ \ \ \ \ (n > 101\ and\ \ }\\
                \mathtt{\ \ \ \ \ \ \ \ \ \ \ \ r = n - 10){]}}
              \end{array}$} (3) 
        (3) edge 
            node [left] {$\mathtt{return\ 0}$} (4)

        (00) edge [bend right=30]
            node [left] {$\mathtt{assume\ m_1 > 100}$} (01)
            edge [bend left=30]
            node [right] {$\mathtt{assume\ not(m_1 > 100)}$} (02)
        (01) edge [bend right=30]
            node [left] {$
              \begin{array}{c}
                \mathtt{r^{mc91} :=}\\
                \mathtt{m_1 - 10}
              \end{array}$} (05)
        (02) edge 
            node [right] {$\mathtt{assume\ false}$} (03)
        (03) edge 
            node [right] {$\mathtt{assume\ false}$} (04)
        (04) edge [bend left=30]
            node [right] {$\mathtt{r^{mc91}_1 := t_1}$} (05)

        (05) edge [bend left=30]
             node [below=8pt] {$\mathtt{r := r^{mc91}_1}$} (2);
    \end{tikzpicture}
  \caption{Under-approximation of McCarthy 91}
  \label{figure:under-mccarthy91}
\end{figure}

When $\method{BasicAnalyzer}$ does not find any error in the
under-approximation $\underline{G}^{\fun{main}}_k$, it computes an inductive
invariant $\Pi (\underline{G}^{\fun{main}}_k, \TT)$. Our algorithm then computes
summaries of functions in \prog{P}. For each function $\fun{f}$ with
formal parameters $\overline{\mathtt{u}}^{\fun{f}}$ and return
variables $\overline{\mathtt{r}}^{\fun{f}}$, a \emph{function summary} for
$\fun{f}$ is a 
first-order conjunctive formula which specifies the relation between
its formal parameters and return variables. The algorithm
ComputeSummary($\prog{P}_k$, $\Pi (\underline{G}^{\fun{main}}_k, \TT)$) computes summaries $S$ by inspecting
the inductive invariant $\Pi (\underline{G}^{\fun{main}}_k, \TT)$~(Section~\ref{sec:computing-summary}).

After function summaries are computed, Algorithm~\ref{algorithm:overview} 
verifies whether function summaries correctly specify computations of
functions by invoking CheckSummary$(\prog{P}_k, S)$.
The algorithm CheckSummary$(\prog{P}_k, S)$ checks this by constructing a recursion-free control flow
graph $\tilde{G}^{\fun{f}}$ with additional assertions for each
function $\fun{f}$ and verifying $\tilde{G}^{\fun{f}}$ with
\method{BasicAnalyzer}. The control flow graph
$\tilde{G}^{\fun{f}}$ is obtained by substituting function
summaries for function calls.
\hide{
 In Algorithm~\ref{algorithm:overview},
$S[\fun{g}]$ contains the function summary for the function
$\fun{g}$.
}
It is transformed from $G^{\fun{f}}$ by the
following three steps:
\begin{enumerate}
\item Replace every function call by instantiating the summary for the
  callee;
\item Replace every return command by assignments to return variables;
\item Add an assertion to validate the summary at the end.
\end{enumerate}
\hide{
\begin{enumerate}
\item Replace every function call $\overline{\mathtt{x}} := \fun{g}
  (\overline{p})$ in $G_{\fun{f}}$ by
  \begin{equation*}
    \begin{array}{l}
      \overline{\mathtt{x}} := \overline{\mathtt{nondet}};\\
      \mathtt{assume}\ 
      S[{\fun{g}}]\{\overline{\mathtt{u}} \mapsto \overline{p},
      \overline{\mathtt{r}}^{\fun{g}} \mapsto \overline{\mathtt{x}}\}
    \end{array}
  \end{equation*}
  where $\overline{\mathtt{u}}^{\fun{g}}$
  are the formal parameters of the function $\fun{g}$;
\item Replace every $\mathtt{return\ } \overline{q}$ command by
  \begin{equation*}
    \overline{\mathtt{r}}^{\fun{f}} := \overline{q}
  \end{equation*}
\item Add the command $\mathtt{assert\ }S[{\fun{f}}]$ at the end of
  $G^{\fun{f}}$.
\end{enumerate}
}
Figure~\ref{figure:check-summary-mccarthy91} shows the control flow
graph $\tilde{G}^{\fun{mc91}}$ with the function summary
$S[{\fun{mc91}}] = \mathtt{not (m \geq 0)}$. Observe that
$\tilde{G}^{\fun{mc91}}$ is
recursion-free. \method{BasicAnalyzer} is able to check
$\tilde{G}^{\fun{mc91}}$ and invalidates this function summary.

\begin{figure}
  \centering
    \begin{tikzpicture}[scale=1.2,->,>=stealth',shorten >=1pt,auto,node
      distance=2cm,thick,node/.style={circle,draw,minimum width=0.8cm,inner sep=0}]
      \node[node,label=above:$\fun{mc91}(\mathtt{n})$] (s) at ( 0,  0) {$s$};
      \node[node] (1) at (-1, -2) {$1$};
      \node[node] (2) at ( 1, -0.8) {$2$};
      \node[node] (3) at ( 1, -2) {$3$};
      \node[node] (4) at ( 1, -3.2) {$4$};
      \node[node] (5) at ( 0, -4) {$5$};
      \node[node] (e) at ( 0, -5) {$e$};

      \path
        (s) edge [bend right=30]
            node [left] {$\mathtt{assume\ m > 100}$} (1)
            edge [bend left=30]
            node [right] {$\mathtt{assume\ not(m > 100)}$} (2)
        (1) edge [bend right=30]
            node [left] {$\mathtt{r^{mc91} := m - 10}$} (5)
        (2) edge 
            node [right] {$
              \begin{array}{l}
              \mathtt{s := nondet;}\\
              \mathtt{assume\ not(m + 11 \geq 0)}
              \end{array}
              $} (3)
        (3) edge 
            node [right] {$
              \begin{array}{l}
              \mathtt{t := nondet;}\\
              \mathtt{assume\ not(s \geq 0)}
              \end{array}$} (4)
        (4) edge [bend left=30]
            node [right] {$\mathtt{r^{mc91} := t}$} (5)
        (5) edge 
            node [right] {$\mathtt{assert\ not(m \geq 0)}$} (e)
        ;
    \end{tikzpicture}
  \caption{Check Summary in McCarthy 91}
  \label{figure:check-summary-mccarthy91}
\end{figure}

In order to refine function summaries, our algorithm unwinds recursive
functions as usual. More precisely, consider a recursive function
$\fun{f}$ with formal parameters $\overline{\mathtt{u}}^{\fun{f}}$
and return variables $\overline{\mathtt{r}}^{\fun{f}}$.
Let $G^{\fun{f}}$ be the control flow graph of $\fun{f}$ and $G^{\fun{main}}_k$
be a control flow graph that invokes $\fun{f}$.
To unwind $\fun{f}$ in $G^{\fun{main}}_k$,
we first construct a control flow graph $H^{\fun{f}}$ by
replacing every $\mathtt{return}\ \overline{q}$ command in
$\fun{f}$ with the assignment $\overline{\mathtt{r}}^{\fun{f}} :=
\overline{q}$. For each edge $(\ell,  
\ell')$ labeled with the command $\overline{\mathtt{x}} :=
\fun{f}(\overline{p})$ in $G^{\fun{main}}_k$, we remove
the edge $(\ell, \ell')$, make a fresh copy $K^{\fun{f}}$ of $H^{\fun{f}}$ by
renaming all nodes and variables, and then add two edges: add an edge
from $\ell$ to the entry node of $K^{\fun{f}}$ that assigns
$\overline{p}$ to fresh copies of formal parameters in 
$K^{\fun{f}}$ and another edge from the exit node to $\ell'$ that
assigns fresh copies of return variables to
$\overline{\mathtt{x}}$. The control flow graph $G^{\fun{main}}_{k+1}$ 
is obtained by unwinding every function call in $G^{\fun{main}}_k$. 
Figure~\ref{figure:unwind-mccarthy91} shows the control flow graph
obtained by unwinding $\fun{main}$ twice. Note that the
unwinding graph $G^{\fun{main}}_{k+1}$ still has recursive function calls. Its
under-approximation $\underline{G}^{\fun{main}}_{k+1}$ is more
accurate than $\underline{G}^{\fun{main}}_k$. 

\begin{figure}
  \centering
  \resizebox{1\textwidth}{!}
  {
    \begin{tikzpicture}[scale=1.2,->,>=stealth',shorten >=1pt,auto,node
      distance=2cm,thick,node/.style={circle,draw,minimum width=0.8cm,inner sep=0}]
      \node[node] (0s) at (-4, 0) {$s$}; %[label=above:$\mathtt{main()}$]
      \node[node] (01) at (-4, -1) {$1$};
      \node[node] (02) at (-4, -2) {$2$};
      \node[node] (03) at (-4, -3) {$3$};
      \node[node] (0e) at (-4, -4) {$e$};

      \node[node] (s) at (-1,  0) {\smallnode{$s_1^{\fun{mc91}}$}};
      \node[node] (1) at (-2, -2) {$1_1$};
      \node[node] (2) at ( 1, -0.8) {$2_1$};
      \node[node] (3) at ( 1, -2) {$3_1$};
      \node[node] (4) at ( 1, -3.2) {$4_1$};
      \node[node] (e) at (-1, -4) {\smallnode{$e_1^{\fun{mc91}}$}};

      \node[node] (s') at ( 5,  2.6) {$s_2$};
      \node[node] (1') at ( 4,  0.6) {$1_2$};
      \node[node] (2') at ( 6,  1.8) {$2_2$};
      \node[node] (3') at ( 6,  0.6) {$3_2$};
      \node[node] (4') at ( 6, -0.6) {$4_2$};
      \node[node] (e') at ( 5, -1.4) {$e_2$};

      \node[node] (s'') at ( 5, -2.6) {$s_3$};
      \node[node] (1'') at ( 4, -4.6) {$1_3$};
      \node[node] (2'') at ( 6, -3.4) {$2_3$};
      \node[node] (3'') at ( 6, -4.6) {$3_3$};
      \node[node] (4'') at ( 6, -5.8) {$4_3$};
      \node[node] (e'') at ( 5, -6.6) {$e_3$};

      \path
        (0s) edge 
            node [left] {$\mathtt{assume\ n >= 0}$} (01)
        (01) edge [bend left=15]
            node [above=2pt] {$\mathtt{m_1 := n}$} (s)
        (02) edge 
            node [left] {$
              \begin{array}{l}
                \mathtt{assert\ {[}r = 91\ or}\\
                \mathtt{\ \ \ \ \ \ \ \ \ \ \ (n > 101\ and\ \ }\\
                \mathtt{\ \ \ \ \ \ \ \ \ \ \ \ r = n - 10){]}}
              \end{array}$} (03) 
        (03) edge 
            node [left] {$\mathtt{return\ 0}$} (0e)


        (s) edge [bend right=30]
            node [right] {$
              \begin{array}{c}
                \mathtt{assume}\\ 
                \mathtt{m_1 > 100}                
              \end{array}$} (1)
            edge [bend left=60]
            node [above] {$
              \begin{array}{l}
                \mathtt{assume}\\
                \mathtt{not(m_1 > 100)\ }
              \end{array}$} (2)
        (1) edge [bend right=30]
            node [above right] {$
              \begin{array}{c}
                \mathtt{r^{mc91}_1 :=}\\
                \mathtt{m_1 - 10}
              \end{array}$} (e)
        (2) edge [bend left=50]
            node [above left] {$\mathtt{m_2 := m_1 + 11}$} (s')
        (3) edge 
            node [below] {$\mathtt{m_3 := s_1}$} (s'')
        (4) edge [bend left=30]
            node [below] {$\mathtt{r^{mc91}_1 := t_1}$} (e)
        (e) edge [bend left=15]
            node [below=9pt] {$\mathtt{r := r^{mc91}_1}$} (02)

        (s') edge [bend right=30]
             node [left] {$
               \begin{array}{c}
                 \mathtt{assume}\\
                 \mathtt{m_2 > 100}
               \end{array}$} (1')
             edge [bend left=30]
             node [right] {$\mathtt{assume\ not(m_2 > 100)}$} (2')
        (1') edge [bend right=30]
             node [left] {$\mathtt{r^{mc91}_2 := m_2 - 10}$} (e')
        (2') edge 
             node [right] {$\mathtt{s_2 := mc91(m_2+11)}$} (3')
        (3') edge 
             node [right] {$\mathtt{t_2 := mc91(s_2)}$} (4')
        (4') edge [bend left=30]
            node [right] {$\mathtt{r^{mc91}_2 := t_2}$} (e')
        (e') edge 
             node [above] {$\mathtt{s_1 := r^{mc91}_2}$} (3)

        (s'') edge [bend right=30]
              node [left] {$\mathtt{assume\ m_3 > 100}$} (1'')
              edge [bend left=30]
              node [right] {$\mathtt{assume\ not(m_3 > 100)}$} (2'')
        (1'') edge [bend right=30]
              node [left] {$
                \begin{array}{c}
                \mathtt{r^{mc91}_3 :=}\\
                \mathtt{m_3 - 10}  
                \end{array}
                $} (e'')
        (2'') edge 
              node [right] {$\mathtt{s_3 := mc91(m_3+11)}$} (3'')
        (3'') edge 
              node [right] {$\mathtt{t_3 := mc91(s_3)}$} (4'')
        (4'') edge [bend left=50]
              node [right] {$\mathtt{r^{mc91}_3 := t_3}$} (e'')
        (e'') edge [bend left=50]
              node [below left] {$\mathtt{t_1 := r^{mc91}_3}$} (4)
        ;
    \end{tikzpicture}
    }
  \caption{Unwinding McCarthy 91}
  \label{figure:unwind-mccarthy91}
\end{figure}
\end{comment}

