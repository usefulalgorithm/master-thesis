\chapter{Discussion}\label{ch:discussion}

For the learning-based procedure, there are several advantages of having a program model with statistical guarantees. For instance, the model can be reused for verifying a different set of the program. Assume that the new property to be proved correct is described as an error path automaton $B'$, and $C$ is the learned automaton. If $L(B') \cap L(C) = \emptyset$, we then have verified the program with a new property and the same $\PAC$ness guarantee. For the case when there exists a decision vector $w \in L(B') \cup L(C)$, we test whether $w$ is feasible and either reports $w$ as a feasible error decision vector with respect to $B'$, or continue the learning algorithm with $w$ as a counterexample for refining the next candidate automaton. 

In this work, we focus on checking the program assertion's validity. For the learning-based procedure, the step is done by making an intersection of the candidate automaton $C$ and the error automaton $B$, and test on the emptiness of this intersection. The process can be generalized to more sophisticated safety properties by replacing the tests $L(C) \cap L(B) = \emptyset$ and $s \in L(B)$ with other tests. For example, we can check the property "the program consists at most 10 consecutive 1-decisions on any path" with a statisctical guarantee of the correctness of the recieved answer. By extending the alphabet {0,1} with program labels, one can also check temporal properties related to those labels, e.g., "label $A$ should be reached within 10 decisions after label $B$ is reached". 

One possible extension of the learning-based approach is to learn sequences of feasible function calls instead of decision vectors. This might lead to a more contrast model in contrast to the current approach. However, in this case the alphabet of the model to be learned will be all function names in the program, which is usually much larger than 2, the size of the alphabet in our work. Moreover, in this setting, it is much harder to answer membership queries; a program path composed of function calls might perform a complex traversal through loops and branches in between the calls, rendering the problem of checking feasibility of a program path undecidable.

A benefit of both of our approaches is that, in principle, they can be extended to checking a black box system's validity and, in the case of our learning-based procedure, model synthesis. By observing the behavior of the environment, we may find some pattern (e.g., some statistical distribution) of inputs, which we can devise a sampling mechanism according to. Under the assumption that the behavior of the environment remains unchanged, we can prove and synthesize the model of the system with respect to the given sample distribution.