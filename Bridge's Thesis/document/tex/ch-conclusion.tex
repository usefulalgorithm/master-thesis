
\chapter{Conclusion}\label{ch:conclusion}

% Extension: using program analyzer + bounded model checking

The number of iterations is perhaps the most important factor in our
recursion analysis technique (Table~\ref{table:experiments}) as it would
determine how many times of unwinding are applied.
We find that \textsc{CPAchecker} performs poorly when checking programs
that is unwound many times.
We however do not enable the more efficient block encoding in
\textsc{CPAchecker} for the ease of implementation.
One can improve the performance of our algorithm with the efficient but
complicated block encoding.
A bounded analyzer may also speed up the verification of bounded properties.

Our algorithm extracts function summaries from inductive invariants.
There are certainly many heuristics to optimize the computation of
function summaries.
For instance, some program analyzers return error traces when properties fail.
In particular, a valuation of formal parameters is obtained when
\textmd{CheckSummary} (Algorithm~\ref{algorithm:check-summary}) returns $\FF$.
If the valuation is not possible in the $\fun{main}$ function, one can use
its inductive invariant to refine function summaries.
We in fact exploit error traces computed by \textsc{CPAchecker} in the
implementation.

Another improvement on our algorithm is on selecting locations for extracting
inductive invariants.
In Algorithm~\ref{algorithm:mark-locations}, we select only outermost pairs of
locations for calls to the same function.
This is based on the observation that the unwound bodies of these function calls
contain more execution paths,
and hence their behaviors should be closer to the original function.
However, the extracted invariants in $s_i$ may be too precise to those certain
function calls and result in too coarse summary candidates constructed by
implication connective,
and consequently the candidates can not pass \textmd{CheckSummary} due to inner
function calls are not properly approximated.
Therefore, heuristics that select some locations of inner function calls may help
compute summary candidates with better quality.

Further enhancement and application of our work would be supporting recursive
data structures and verifying operations on the data structure.
Common recursive functions in real world C program mostly are simple operations
on recursive data structures, such as list, tree, graph, etc.,
but our prototype currently only verifies integer programs.
If our approach is adapted to handle data structures, a dedicated logic is
required for describing data structure as well as semantic for the operations,
and a \method{BasicAnalyzer} providing inductive invariants in such logic surely
is necessary.
Our primitive study reveals several difficulties on applying our approach with
separation logic~\cite{Reynolds02} and the \textsc{Thor}
analyzer~\cite{MagillTLT08}.

One major obstacle comes from \textmd{ComputeSummary} and \textmd{CheckSummary}.
In our method, implication connective and universal quantification are used to
derive summary.
These operators are intuitive in propositional and Presburger arithmetic logic.
By contrast, there is no such operator on separation logic.
Consequently, we tried to devise different methods for compute and check
summaries in order to avoid the usage of the operators.
A possible workaround for this problem is to use multiple formulae instead of
one single formula to represent one function summary.

Another problem arises from the expression allowed in $\mathtt{assume}$ and
$\mathtt{assert}$ command.
Our program model does not introduce a separated \emph{assertion language} for
specifying preconditions and postconditions,
and this is to comply with the assertions in C language.
The drawback of this choice is that the expressiveness and grammar of allowed
boolean expression in program is limited,
and hence not necessarily consistent with the logic in \method{BasicAnalyzer}.
To precisely describe a recursive data structure, we tried to introduce
annotations recognized by \method{BasicAnalyzer} into C programs.
In our study, we actually used the assertion language defined by \textsc{Thor}
to annotate C programs,
and much more efforts are needed to understand the underlying analyzer,
not to mention the transformation on the formulae.

Finally, reducing program features via program transformation techniques is the
core concept of our work.
We believe this idea can be applied to deal with other kinds of program
features, such as pointers, unbounded integral types, procedure calls through
dynamic look up, absent code due to external libraries, etc.
Program analysis tools can rely on one efficient and simple core
\method{BasicAnalyzer} and modular components doing transformation for different
program features.
The development tasks for the tools could be easily divided and dispatched,
and optimization for different components could be independent and loosely
coupled.
Overall, we believe the concept could speed up the process of research as well
as implementation on program analysis.
